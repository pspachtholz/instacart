order_products %>%
left_join(orders,by="order_id") %>%
group_by(days_since_prior_order) %>%
summarize(mean_reorder = mean(reordered)) %>%
ggplot(aes(x=days_since_prior_order,y=mean_reorder))+
geom_bar(stat="identity",fill="red")
order_products %>%
group_by(product_id) %>%
summarize(proportion_reordered = mean(reordered), n=n()) %>%
ggplot(aes(x=n,y=proportion_reordered))+
geom_point()+
geom_smooth(color="red")+
coord_cartesian(xlim=c(0,2000))
products
head(products)
str_detect(str_to_lower(products$product_name),'organic')
sum(str_detect(str_to_lower(products$product_name),'organic'))
sum(str_detect(products$product_name,'organic'))
sum(str_detect(products$product_name,'Organic'))
install.packages(c("curl", "DBI", "dplyr", "evaluate", "ggExtra", "quantmod", "R6", "rgdal", "rmarkdown", "shinyjs", "sp", "visNetwork", "XML"))
devtools::install_github("Microsoft/LightGBM", subdir = "R-package")
install.packages("devtools")
devtools::install_github("Microsoft/LightGBM", subdir = "R-package")
devtools::install_github("Microsoft/LightGBM", subdir = "R-package")
devtools::install_github("Microsoft/LightGBM", subdir = "R-package")
devtools::install_github("Microsoft/LightGBM@v1", subdir = "R-package")
devtools::install_github("Microsoft/LightGBM", subdir = "R-package")
devtools::install_github("Laurae2/lgbdl")
lgb.dl(commit = "master",
compiler = "gcc",
repo = "https://github.com/Microsoft/LightGBM",
cores = 4)
library(lgbdl)
lgb.dl(commit = "master",
compiler = "gcc",
repo = "https://github.com/Microsoft/LightGBM",
cores = 4)
lgb.dl(commit = "master",
compiler = "gcc",
repo = "https://github.com/Microsoft/LightGBM",
cores = 4)
lgb.dl(commit = "master",
repo = "https://github.com/Microsoft/LightGBM",
cores = 4)
lgb.dl(commit = "master",
repo = "https://github.com/Microsoft/LightGBM",
cores = 4)
lgb.dl(commit = "master",
repo = "https://github.com/Microsoft/LightGBM",
cores = 4)
lgb.dl(commit = "master",
repo = "https://github.com/Microsoft/LightGBM",
cores = 4)
lgb.dl(commit = "master",
repo = "https://github.com/Microsoft/LightGBM",
cores = 4)
lgb.dl(commit = "master",
repo = "https://github.com/Microsoft/LightGBM",
cores = 4, compiler="gcc")
lgb.dl(commit = "master",
repo = "https://github.com/Microsoft/LightGBM",
cores = 4, compiler="gcc")
rm(list=ls())
gc()
library(data.table)
library(dplyr)
library(tidyr)
library(lightgbm)
library(stringr)
library(ModelMetrics)
setwd("D:/Eigene Dateien/sonstiges/Kaggle/instacart/scripts")
f1 <- function (y, pred)
{
tp <- sum(pred==1 & y == 1)
fp <- sum(pred==1 & y == 0)
fn <- sum(pred==0 & y == 1)
precision <- ifelse ((tp==0 & fp==0), 0, tp/(tp+fp))
recall <- ifelse ((tp==0 & fn==0), 0, tp/(tp+fn))
score <- ifelse ((precision==0 & recall==0), 0, 2*precision*recall/(precision+recall))
score
}
# Load Data ---------------------------------------------------------------
path <- "../input"
aisles <- fread(file.path(path, "aisles.csv"))
departments <- fread(file.path(path, "departments.csv"))
opp <- fread(file.path(path, "order_products__prior.csv"))
opt <- fread(file.path(path, "order_products__train.csv"))
ord <- fread(file.path(path, "orders.csv"))
products <- fread(file.path(path, "products.csv"))
# Reshape data ------------------------------------------------------------
aisles$aisle <- as.factor(aisles$aisle)
departments$department <- as.factor(departments$department)
ord$eval_set <- as.factor(ord$eval_set)
products$product_name <- as.factor(products$product_name)
products <- products %>%
inner_join(aisles) %>% inner_join(departments) %>%
select(-aisle_id, -department_id)
rm(aisles, departments)
# add user_id to train orders
opt$user_id <- ord$user_id[match(opt$order_id, ord$order_id)]
op <- ord %>% inner_join(opp, by = "order_id")
class(ord)
class(opp)
op2 <- ord[opp, nomatch=0]
setkey(opp,order_id)
op2 <- ord[opp, nomatch=0]
setkey(ord,order_id)
op2 <- ord[opp, nomatch=0]
identical(op,op2)
head(op2)
head(op)
op <- ord[opp,nomatch=0]
setkeyv(op,c("user_id","product_id"))
op[,num_order := length(unique(order_id)),.(user_id)]
op[,c("product_time2","first_order","last_order","sum_order") := .(1:.N,order_number[1],order_number[.N],.N),.(user_id,product_id)]
rm(opp)
gc()
glimpse(opp)
glimpse(op)
View(head(op,100))
op[,c("product_time2","first_order","last_order","sum_order") := .(1:.N,min(order_number),max(order_number),.N),.(user_id,product_id)]
View(head(op,100))
prd2 <- op %>%
arrange(user_id, order_number, product_id) %>%
group_by(user_id, product_id) %>%
mutate(product_time = row_number()) %>%
ungroup() %>%
group_by(product_id) %>%
summarise( #per product
prod_orders = n(),
prod_reorders = sum(reordered),
prod_first_orders = sum(product_time == 1),
prod_second_orders = sum(product_time == 2)
)
head(prd2)
head(op)
prd <- op[, .(prod_reorders = sum(reordered)),by=product_id]
head(prd)
head(prd2)
filter(prd2,product_id==196)
head(op)
prd <- op[, .(prod_orders = .N, prod_reorders = sum(reordered), prod_first_orders = sum(product_time==1), prod_second_orders = sum(product_time==2), prod_add_to_cart = mean(add_to_cart_order), prod_inpercent_orders=mean(sum_order)/mean(num_order), prod_inpercent_afterfirst = sum_order/(num_order-first_order+1)),by=product_id]
rm(list=ls())
gc()
library(data.table)
library(dplyr)
library(tidyr)
library(lightgbm)
library(stringr)
library(ModelMetrics)
setwd("D:/Eigene Dateien/sonstiges/Kaggle/instacart/scripts")
f1 <- function (y, pred)
{
tp <- sum(pred==1 & y == 1)
fp <- sum(pred==1 & y == 0)
fn <- sum(pred==0 & y == 1)
precision <- ifelse ((tp==0 & fp==0), 0, tp/(tp+fp))
recall <- ifelse ((tp==0 & fn==0), 0, tp/(tp+fn))
score <- ifelse ((precision==0 & recall==0), 0, 2*precision*recall/(precision+recall))
score
}
# Load Data ---------------------------------------------------------------
path <- "../input"
aisles <- fread(file.path(path, "aisles.csv"))
departments <- fread(file.path(path, "departments.csv"))
opp <- fread(file.path(path, "order_products__prior.csv"))
opt <- fread(file.path(path, "order_products__train.csv"))
ord <- fread(file.path(path, "orders.csv"))
products <- fread(file.path(path, "products.csv"))
# Reshape data ------------------------------------------------------------
aisles$aisle <- as.factor(aisles$aisle)
departments$department <- as.factor(departments$department)
ord$eval_set <- as.factor(ord$eval_set)
products$product_name <- as.factor(products$product_name)
products <- products %>%
inner_join(aisles) %>% inner_join(departments) %>%
select(-aisle_id, -department_id)
rm(aisles, departments)
# add user_id to train orders
opt$user_id <- ord$user_id[match(opt$order_id, ord$order_id)]
# join products with order info for all prior orders
setkey(ord,order_id)
setkey(opp,order_id)
op <- ord[opp,nomatch=0]
# data.table is way faster
setkeyv(op,c("user_id","product_id"))
op[,num_order := length(unique(order_id)),.(user_id)]
op[,c("product_time","first_order","last_order","sum_order") := .(1:.N,min(order_number),max(order_number),.N),.(user_id,product_id)]
rm(opp)
gc()
prd2 <- op %>%
arrange(user_id, order_number, product_id) %>%
group_by(user_id, product_id) %>%
mutate(product_time = row_number()) %>%
ungroup() %>%
group_by(product_id) %>%
summarise( #per product
prod_orders = n(),
prod_reorders = sum(reordered),
prod_first_orders = sum(product_time == 1),
prod_second_orders = sum(product_time == 2)
)
prd <- op[, .(prod_orders = .N,
prod_reorders = sum(reordered),
prod_first_orders = sum(product_time==1),
prod_second_orders = sum(product_time==2),
prod_add_to_cart = mean(add_to_cart_order),
prod_inpercent_orders=mean(sum_order)/mean(num_order),
prod_inpercent_afterfirst = mean(sum_order)/(mean(num_order)-mean(first_order)+1)),
by=product_id]
head(prd)
prd <- op[, .(prod_orders = .N,
prod_reorders = sum(reordered),
prod_first_orders = sum(product_time==1),
prod_second_orders = sum(product_time==2),
prod_add_to_cart = mean(add_to_cart_order),
prod_inpercent_orders=mean(sum_order)/mean(num_order),
prod_inpercent_afterfirst = mean(sum_order)/(mean(num_order)-mean(first_order)+1)),
by=product_id][, ':=' (prod_reorder_probability = prod_second_orders / prod_first_orders)]
head(prd)
filter(prd2, product_id==196)
prd2$prod_reorder_probability <- prd$prod_second_orders / prd$prod_first_orders #
prd2$prod_reorder_probability <- prd2$prod_second_orders / prd2$prod_first_orders #
filter(prd2, product_id==196)
prd <- op[, .(prod_orders = .N,
prod_reorders = sum(reordered),
prod_first_orders = sum(product_time==1),
prod_second_orders = sum(product_time==2),
prod_add_to_cart = mean(add_to_cart_order),
prod_inpercent_orders=mean(sum_order)/mean(num_order),
prod_inpercent_afterfirst = mean(sum_order)/(mean(num_order)-mean(first_order)+1)),
by=product_id][, ':=' (prod_reorder_probability = prod_second_orders / prod_first_orders,
prod_reorder_times = 1 + prode_reorders / prod_first_orders,
prod_reorder_ratio = prod_reorders / prod_orders)]
prd <- op[, .(prod_orders = .N,
prod_reorders = sum(reordered),
prod_first_orders = sum(product_time==1),
prod_second_orders = sum(product_time==2),
prod_add_to_cart = mean(add_to_cart_order),
prod_inpercent_orders=mean(sum_order)/mean(num_order),
prod_inpercent_afterfirst = mean(sum_order)/(mean(num_order)-mean(first_order)+1)),
by=product_id][, ':=' (prod_reorder_probability = prod_second_orders / prod_first_orders,
prod_reorder_times = 1 + prod_reorders / prod_first_orders,
prod_reorder_ratio = prod_reorders / prod_orders)]
head(prd)
head(op)
rm(list=ls())
gc()
library(data.table)
library(dplyr)
library(tidyr)
library(lightgbm)
library(stringr)
library(ModelMetrics)
setwd("D:/Eigene Dateien/sonstiges/Kaggle/instacart/scripts")
f1 <- function (y, pred)
{
tp <- sum(pred==1 & y == 1)
fp <- sum(pred==1 & y == 0)
fn <- sum(pred==0 & y == 1)
precision <- ifelse ((tp==0 & fp==0), 0, tp/(tp+fp))
recall <- ifelse ((tp==0 & fn==0), 0, tp/(tp+fn))
score <- ifelse ((precision==0 & recall==0), 0, 2*precision*recall/(precision+recall))
score
}
# Load Data ---------------------------------------------------------------
path <- "../input"
aisles <- fread(file.path(path, "aisles.csv"))
departments <- fread(file.path(path, "departments.csv"))
opp <- fread(file.path(path, "order_products__prior.csv"))
opt <- fread(file.path(path, "order_products__train.csv"))
ord <- fread(file.path(path, "orders.csv"))
products <- fread(file.path(path, "products.csv"))
# Reshape data ------------------------------------------------------------
aisles$aisle <- as.factor(aisles$aisle)
departments$department <- as.factor(departments$department)
ord$eval_set <- as.factor(ord$eval_set)
products$product_name <- as.factor(products$product_name)
products <- products %>%
inner_join(aisles) %>% inner_join(departments) %>%
select(-aisle_id, -department_id)
rm(aisles, departments)
# add user_id to train orders
opt$user_id <- ord$user_id[match(opt$order_id, ord$order_id)]
# join products with order info for all prior orders
setkey(ord,order_id)
setkey(opp,order_id)
op <- ord[opp,nomatch=0]
# data.table is way faster
setkeyv(op,c("user_id","product_id", "order_number"))
op[,num_order := length(unique(order_id)),.(user_id)]
op[,c("product_time","first_order","second_order", "last_order","sum_order") := .(1:.N,min(order_number),oder_number[2], max(order_number),.N),.(user_id,product_id)]
rm(opp)
gc()
op[,c("product_time","first_order","second_order", "last_order","sum_order") := .(1:.N,min(order_number),order_number[2], max(order_number),.N),.(user_id,product_id)]
head(op)
head(op,100)
prd <- op[, .(prod_orders = .N,
prod_reorders = sum(reordered),
prod_first_orders = sum(product_time==1),
prod_second_orders = sum(product_time==2),
prod_add_to_cart = mean(add_to_cart_order),
prod_inpercent_orders=mean(sum_order)/mean(num_order),
prod_inpercent_afterfirst = mean(sum_order)/(mean(num_order)-mean(first_order)+1),
prod_popularity = length(unique(user_id)),
prod_orders_till_reorder = second_order-first_order),by=product_id][,
':=' (prod_reorder_probability = prod_second_orders / prod_first_orders,
prod_reorder_times = 1 + prod_reorders / prod_first_orders,
prod_reorder_ratio = prod_reorders / prod_orders)]
head(prd)
setkeyv(op,c("user_id","product_id"))
prd <- op[, .(prod_orders = .N,
prod_reorders = sum(reordered),
prod_first_orders = sum(product_time==1),
prod_second_orders = sum(product_time==2),
prod_add_to_cart = mean(add_to_cart_order),
prod_inpercent_orders=mean(sum_order)/mean(num_order),
prod_inpercent_afterfirst = mean(sum_order)/(mean(num_order)-mean(first_order)+1),
prod_popularity = length(unique(user_id)),
prod_orders_till_reorder = second_order-first_order),by=product_id][,
':=' (prod_reorder_probability = prod_second_orders / prod_first_orders,
prod_reorder_times = 1 + prod_reorders / prod_first_orders,
prod_reorder_ratio = prod_reorders / prod_orders)]
head(prd)
prd <- op[, .(prod_orders = .N,
prod_reorders = sum(reordered),
prod_first_orders = sum(product_time==1),
prod_second_orders = sum(product_time==2),
prod_add_to_cart = mean(add_to_cart_order),
prod_inpercent_orders=mean(sum_order)/mean(num_order),
prod_inpercent_afterfirst = mean(sum_order)/(mean(num_order)-mean(first_order)+1),
prod_popularity = mean(length(unique(user_id))),
prod_orders_till_reorder = second_order-first_order),by=product_id][,
':=' (prod_reorder_probability = prod_second_orders / prod_first_orders,
prod_reorder_times = 1 + prod_reorders / prod_first_orders,
prod_reorder_ratio = prod_reorders / prod_orders)]
head(prd)
prd <- op[, .(prod_orders = .N,
prod_reorders = sum(reordered),
prod_first_orders = sum(product_time==1),
prod_second_orders = sum(product_time==2),
prod_add_to_cart = mean(add_to_cart_order),
prod_inpercent_orders=mean(sum_order)/mean(num_order),
prod_inpercent_afterfirst = mean(sum_order)/(mean(num_order)-mean(first_order)+1),
prod_popularity = mean(length(unique(user_id))),
prod_orders_till_reorder = mean(second_order-first_order)),by=product_id][,
':=' (prod_reorder_probability = prod_second_orders / prod_first_orders,
prod_reorder_times = 1 + prod_reorders / prod_first_orders,
prod_reorder_ratio = prod_reorders / prod_orders)]
head(prd)
prd <- op[, .(prod_orders = .N,
prod_reorders = sum(reordered),
prod_first_orders = sum(product_time==1),
prod_second_orders = sum(product_time==2),
prod_add_to_cart = mean(add_to_cart_order),
prod_inpercent_orders=mean(sum_order)/mean(num_order),
prod_inpercent_afterfirst = mean(sum_order)/(mean(num_order)-mean(first_order)+1),
prod_popularity = mean(length(unique(user_id))),
prod_orders_till_reorder = mean(second_order-first_order,na.rm=T)),by=product_id][,
':=' (prod_reorder_probability = prod_second_orders / prod_first_orders,
prod_reorder_times = 1 + prod_reorders / prod_first_orders,
prod_reorder_ratio = prod_reorders / prod_orders)]
head(prd)
prd <- prd %>% select(-prod_reorders, -prod_first_orders, -prod_second_orders)
prd <- products %>% mutate(organic = ifelse(str_detect(str_to_lower(product_name),'organic'),1,0)) %>% select(product_id, organic) %>% right_join(prd, by="product_id")
head(prd)
rm(products)
gc()
# Users -------------------------------------------------------------------
users <- ord %>%
filter(eval_set == "prior") %>%
group_by(user_id) %>%
summarise(
user_orders = max(order_number),
user_period = sum(days_since_prior_order, na.rm = T),
user_mean_days_since_prior = mean(days_since_prior_order, na.rm = T)
)
us <- op %>%
group_by(user_id) %>%
summarise(
user_total_products = n(),
user_reorder_ratio = sum(reordered == 1) / sum(order_number > 1),
user_distinct_products = n_distinct(product_id)
)
users <- users %>% inner_join(us)
users$user_average_basket <- users$user_total_products / users$user_orders
us <- ord %>%
filter(eval_set != "prior") %>%
select(user_id, order_id, eval_set,
time_since_last_order = days_since_prior_order)
users <- users %>% inner_join(us)
rm(us)
gc()
# Database ----------------------------------------------------------------
data <- op %>%
group_by(user_id, product_id) %>%
summarise(
up_orders = n(),
up_first_order = min(order_number),
up_last_order = max(order_number),
up_average_cart_position = mean(add_to_cart_order))
rm(op, ord)
data <- data %>%
inner_join(prd, by = "product_id") %>%
inner_join(users, by = "user_id")
data$up_order_rate <- data$up_orders / data$user_orders
data$up_orders_since_last_order <- data$user_orders - data$up_last_order
data$up_order_rate_since_first_order <- data$up_orders / (data$user_orders - data$up_first_order + 1)
data <- data %>%
left_join(opt %>% select(user_id, product_id, reordered),
by = c("user_id", "product_id"))
rm(opt, prd, users)
gc()
# Train / Test datasets ---------------------------------------------------
train <- as.data.frame(data[data$eval_set == "train",])
train$eval_set <- NULL
train$user_id <- NULL
train$product_id <- NULL
train$order_id <- NULL
train$reordered[is.na(train$reordered)] <- 0
test <- as.data.frame(data[data$eval_set == "test",])
test$eval_set <- NULL
test$user_id <- NULL
test$reordered <- NULL
rm(data)
gc()
# Model -------------------------------------------------------------------
library(xgboost)
params <- list(
"objective"           = "reg:logistic",
"eval_metric"         = "logloss",
"eta"                 = 0.1,
"max_depth"           = 6,
"min_child_weight"    = 10,
"gamma"               = 0.70,
"subsample"           = 0.76,
"colsample_bytree"    = 0.95,
"alpha"               = 2e-05,
"lambda"              = 10
)
subtrain <- train %>% sample_frac(0.1)
X <- xgb.DMatrix(as.matrix(subtrain %>% select(-reordered)), label = subtrain$reordered)
model <- xgboost(data = X, params = params, nrounds = 80)
importance <- xgb.importance(colnames(X), model = model)
xgb.ggplot.importance(importance)
rm(X, importance, subtrain)
gc()
# Apply model -------------------------------------------------------------
X <- xgb.DMatrix(as.matrix(test %>% select(-order_id, -product_id)))
test$reordered <- predict(model, X)
test$reordered <- (test$reordered > 0.18) * 1
submission <- test %>%
filter(reordered == 1) %>%
group_by(order_id) %>%
summarise(
products = paste(product_id, collapse = " ")
)
missing <- data.frame(
order_id = unique(test$order_id[!test$order_id %in% submission$order_id]),
products = "None"
)
submission <- submission %>% bind_rows(missing) %>% arrange(order_id)
write.csv(submission, file = "submit.csv", row.names = F)
test$reordered <- predict(model, X)
test$reordered <- (test$reordered > 0.21) * 1
submission <- test %>%
filter(reordered == 1) %>%
group_by(order_id) %>%
summarise(
products = paste(product_id, collapse = " ")
)
missing <- data.frame(
order_id = unique(test$order_id[!test$order_id %in% submission$order_id]),
products = "None"
)
submission <- submission %>% bind_rows(missing) %>% arrange(order_id)
write.csv(submission, file = "submit.csv", row.names = F)
head(train)
params <- list(
"objective"           = "reg:logistic",
"eval_metric"         = "logloss",
"eta"                 = 0.1,
"max_depth"           = 6,
"min_child_weight"    = 10,
"gamma"               = 0.70,
"subsample"           = 0.76,
"colsample_bytree"    = 0.9,
"alpha"               = 2e-05,
"lambda"              = 10
)
subtrain <- train %>% sample_frac(0.2)
X <- xgb.DMatrix(as.matrix(subtrain %>% select(-reordered)), label = subtrain$reordered)
model <- xgboost(data = X, params = params, nrounds = 80)
importance <- xgb.importance(colnames(X), model = model)
xgb.ggplot.importance(importance)
importance
# Apply model -------------------------------------------------------------
X <- xgb.DMatrix(as.matrix(test %>% select(-order_id, -product_id)))
test$reordered <- predict(model, X)
test$reordered <- (test$reordered > 0.16) * 1
submission <- test %>%
filter(reordered == 1) %>%
group_by(order_id) %>%
summarise(
products = paste(product_id, collapse = " ")
)
missing <- data.frame(
order_id = unique(test$order_id[!test$order_id %in% submission$order_id]),
products = "None"
)
submission <- submission %>% bind_rows(missing) %>% arrange(order_id)
write.csv(submission, file = "submit.csv", row.names = F)
