tmp_ppsqm <- mean(tmp$price_doc/tmp$full_sq)
} else {
tmp <- train %>% filter(str_detect(train$appartment_name,str_c('^',str_split(errors$appartment_name[i],' ')[[1]][1])), product_type=="OwnerOccupier")
tmp_ppsqm <- mean(tmp$price_doc/tmp$full_sq)
}
errors$price_doc[i] <- round(tmp_ppsqm*errors$full_sq[i])
}
train$price_doc[match(errors$id,train$id)]<-errors$price_doc
train <- train %>% mutate(price_persqm = price_doc/full_sq)
### full_sq < life_sq
## train
# 7478 -> 76
train$life_sq[train$id==13549]<-76
# full 82 life 802
train$life_sq[train$id==9649]<-82
train$life_sq[train$id==1866]<-18
train$life_sq[train$id==22788]<-63.7
train <- train %>% mutate(life_sq=ifelse(life_sq/3>full_sq,life_sq/10, life_sq))
train[!is.na(train$full_sq) & !is.na(train$life_sq) & train$full_sq<train$life_sq,c("full_sq", "life_sq")] <- train[!is.na(train$full_sq) & !is.na(train$life_sq) & train$full_sq<train$life_sq,c("life_sq", "full_sq")]
## test
test <- test %>% mutate(life_sq=ifelse(life_sq/3>full_sq,life_sq/10, life_sq))
test[!is.na(test$full_sq) & !is.na(test$life_sq) & test$full_sq<test$life_sq,c("full_sq", "life_sq")] <- test[!is.na(test$full_sq) & !is.na(test$life_sq) & test$full_sq<test$life_sq,c("life_sq", "full_sq")]
######## kitchen square ###########
## train
train$kitch_sq[train$kitch_sq>1000]<-NA
train$build_year[train$id==13120]<-1970
train$kitch_sq[train$id==11523]<-6
train$kitch_sq[train$id==26239]<-0
train$kitch_sq[train$id==29000]<-17
train$kitch_sq[train$id==26853]<-8
train$kitch_sq[train$id==9175]<-7
train$kitch_sq[train$id==12248]<-3
train$kitch_sq[train$id==23219]<-4
## test
test$kitch_sq[test$kitch_sq>=1000]<-NA
test$kitch_sq[test$id==34333] <- test$kitch_sq[test$id==34333]/10
test$kitch_sq[test$id==32505] <- 1
test$kitch_sq[test$id==36970] <- test$kitch_sq[test$id==36970]/10
######## number of rooms ############
## train
train <- train %>% mutate(sq_proom = full_sq/num_room)
#train %>% select(id, timestamp, price_doc, full_sq, life_sq, kitch_sq, num_room, sq_proom, floor, max_floor, appartment_name, n, everything()) %>% View()
train$num_room[train$id %in% c(11624,26716, 25654, 11020, 17431, 13425,14592,12201)] <- 1 # 17 and 19 rooms
train$num_room[train$id %in% c(17767,19393)] <- 2
train$max_floor[train$id %in% c(17767)] <- 10 # swapped
train$num_room[train$id %in% c(26002)] <- 1
train$max_floor[train$id %in% c(26002)] <- 5 # swapped
train$num_room[train$id %in% c(29175)] <- 2
test <- test %>% mutate(sq_proom = full_sq/num_room)
#test %>% select(id, timestamp, full_sq, life_sq, kitch_sq, num_room, sq_proom, floor, max_floor, appartment_name, n, everything()) %>% View()
## test
test$full_sq[test$id==36824]<-47
test$life_sq[test$id==36824]<-1
test$num_room[test$id %in% c(37787,33648,31903,31891)]<-1
######## floor ###########
## train
train$floor[train$id==23587]<-7
######## max_floor ######
train$max_floor[train$id==20725]<-NA
train$max_floor[train$id==24023]<-NA
train$max_floor[train$id==21737]<-17
train$max_floor[train$id==25943]<-17
train$max_floor[train$id==21855]<-25
######## state #####
train$state[train$id==10092]<-3
#arrange(train,desc(price_persqm)) %>% select(id,price_persqm, price_doc,price_doc2, full_sq, full_sq2, product_type, year, appartment_name, appartment_price, n, everything()) %>% View()
#arrange(train,desc(price_persqm)) %>% select(id,price_persqm, price_doc,price_doc2, full_sq, full_sq2, product_type, year, appartment_name, appartment_price, n, everything()) %>% View()
#train %>% ggplot(aes(x=year, y=full_sq))+geom_line(stat="summary", color="red")+geom_point(stat="summary", size=3, color="red")
#data.frame(t(sort(cor(train[sapply(train, is.numeric)])[,"year"],decreasing=T))) %>% gather() %>% ggplot(aes(x=reorder(key,value),y=value))+geom_bar(stat="identity")+coord_flip()
# equalize strange price docs in every year
re_investment <- train %>%
mutate(year=str_sub(timestamp,1,4)) %>%
filter(product_type=='Investment',year>='2011') %>%
group_by(year) %>%
summarise(n=n(),
n1M=sum(ifelse(price_doc<=1000000,1,0))/n(),
n2M=sum(ifelse(price_doc==2000000,1,0))/n(),
n3M=sum(ifelse(price_doc==3000000,1,0))/n(),
nn1M=n1M*n(),
nn2M=n2M*n(),
nn3M=n3M*n())
goal <- re_investment %>% filter(year==2015) %>% mutate(n1M = n1M/2, n2M=n2M/3, n3M=n3M/2)
re_investment<-re_investment %>%
mutate(m1M = n1M/goal$n1M, m2M=n2M/goal$n2M, m3M = n3M/goal$n3M) %>%
mutate(smp1M = floor(n*n1M/m1M), smp2M = floor(n*n2M/m2M), smp3M = floor(n*n3M/m3M))
## tmp = sampled strange price docs
years <- 2011:2015
tmp <- list()
for (i in seq_along(years)){
tmp[[i]] <- bind_rows(sample_n(filter(train,product_type=='Investment'&year==years[i]&price_doc<=1000000),re_investment$smp1M[re_investment$year==years[i]],replace=TRUE),
sample_n(filter(train,product_type=='Investment'&year==years[i]&price_doc==2000000),re_investment$smp2M[re_investment$year==years[i]], replace=TRUE),
sample_n(filter(train,product_type=='Investment'&year==years[i]&price_doc==3000000),re_investment$smp3M[re_investment$year==years[i]],replace=TRUE))
}
tmp <- bind_rows(tmp)
# tmp2 = normal price docs
tmp2 <- train %>% filter((product_type=='OwnerOccupier') | (between(year, 2011, 2015) & product_type =='Investment' & price_doc > 1000000 & price_doc != 2000000 & price_doc != 3000000))
train <- bind_rows(tmp, tmp2) %>% arrange(id)
test <- test %>% mutate(product_type=as.character(product_type))
test <- test %>% mutate(product_type = ifelse(is.na(product_type) & build_year>2016,"OwnerOccupier",product_type)) # OwnerOccupier
test <- test %>% mutate(product_type = ifelse(is.na(product_type),"Investment",product_type)) # Investment
test <- test %>% mutate(product_type = as.factor(product_type))
# number of floors to the top of house
train <- train %>% mutate(floor_from_top = max_floor - floor)
test <- test %>% mutate(floor_from_top = max_floor - floor)
# relative position of floor in house
train <- train %>% mutate(floor_by_maxfloor = floor/max_floor)
test <- test %>% mutate(floor_by_maxfloor = floor/max_floor)
# average room size
train <- train %>% mutate(roomsize = full_sq/num_room)
test <- test %>% mutate(roomsize = full_sq/num_room)
# relative proportion of living area
train <- train %>% mutate(life_proportion = life_sq/full_sq)
test <- test %>% mutate(life_proportion = life_sq/full_sq)
# relative proportion of kitchen area
train <- train %>% mutate(kitchen_proportion = kitch_sq/full_sq)
test <- test %>% mutate(kitchen_proportion = kitch_sq/full_sq)
# extra area
train <- train %>% mutate(extra_area = full_sq - life_sq)
test <- test %>% mutate(extra_area = full_sq - life_sq)
# kitch diff
train <- train %>% mutate(kitch_diff = full_sq - kitch_sq)
test <- test %>% mutate(kitch_diff = full_sq - kitch_sq)
# age of house at time of sale
train <- train %>% mutate(age_at_sale = year(timestamp)-build_year)
test <- test %>% mutate(age_at_sale = year(timestamp)-build_year)
# ab vom schuss
train <- train %>% mutate(ab_vom_schuss = public_transport_station_km * kremlin_km)
test <- test %>% mutate(ab_vom_schuss = public_transport_station_km * kremlin_km)
sample_submission <- read.csv("../input/sample_submission.csv")
# normalize price_doc
train <- train %>% group_by(product_type, year_quarter) %>% mutate(price_norm = (price_doc-mean(price_doc,na.rm=T))/sd(price_doc,na.rm=T)) %>% ungroup()
# normalize full_sq
train <- train %>% group_by(product_type,year_quarter) %>% mutate(full_sq_norm =(full_sq-mean(full_sq,na.rm=T))/sd(full_sq,na.rm=T)) %>% ungroup()
test <- test %>% group_by(product_type,year_quarter) %>% mutate(full_sq_norm =(full_sq-mean(full_sq,na.rm=T))/sd(full_sq,na.rm=T)) %>% ungroup()
cv <- train %>% filter(year==2012)
cv_id <- cv$id
train <- train %>% filter(!is.na(price_norm) & year >= 2011)
train_id <- setdiff(train$id,cv_id)
train$product_type <- as.factor(train$product_type)
x_train <- train %>%
select(-c(id, timestamp, price_doc, price_persqm, price_doc2, appartment_name, n, year,year_quarter, sq_proom, year_month))
y_train <- x_train$price_norm
x_train <- select(x_train, -price_norm)
x_cv <- cv %>%
select(-c(id, timestamp, price_doc, price_persqm, price_doc2, appartment_name, n, year,year_quarter, sq_proom, year_month))
y_cv <- x_cv$price_norm
x_cv <- select(x_cv, -price_norm)
x_test <- test %>% select(-c(id, timestamp, appartment_name, n, year,year_month, year_quarter, sq_proom))
len_train <- nrow(x_train)
len_cv <- nrow(x_cv)
len_test <- nrow(x_test)
full <- bind_rows(x_train, x_cv, x_test)
features <- colnames(full)
# yearly folds for CV
rownums <- 1:dim(train)[1]
cuts<-cut(rownums,5,labels=FALSE)
folds <- split(rownums, cuts)
for (f in features) {
if ((class(full[[f]])=="factor") || (class(full[[f]])=="character")) {
#cat("VARIABLE : ",f,"\n")
levels <- unique(full[[f]])
full[[f]] <- as.numeric(factor(full[[f]], levels=levels))
}
if (class(full[[f]])=="Date"){
full[[f]]<-as.numeric(full[[f]])
}
}
x_train = full[1:len_train,]
x_cv = full[(len_train+1):(len_train+len_cv),]
x_test = full[(len_train+len_cv+1):(len_train+len_cv+len_test),]
dtrain = xgb.DMatrix(as.matrix(x_train), label=y_train)
dcv = xgb.DMatrix(as.matrix(x_cv), label=y_cv)
dtest = xgb.DMatrix(as.matrix(x_test))
xgb_params = list(
seed = 0,
colsample_bytree = 1,
subsample = 1,
eta = 0.05,
objective = 'reg:linear',
max_depth = 5,
num_parallel_tree = 1,
min_child_weight = 2
)
# result = xgb.train(xgb_params, dtrain, 840, watchlist=list(train=dtrain,validation=dcv))
res = xgb.cv(xgb_params,
dtrain,
nrounds=2000,
nfold=5,
early_stopping_rounds=50,
print_every_n = 10,
verbose= 1,
maximize=FALSE,
prediction=TRUE,
folds = folds)
best_nrounds = res$best_iteration
gbdt = xgb.train(xgb_params, dtrain, best_nrounds)
cv_prediction <- predict(gbdt, dcv)
#rmse
sqrt(mean((cv_prediction-y_cv)^2))
# #rmsle
# cv2 <- cv %>% bind_cols(data.frame(pred=cv_prediction))
# cv2 <- train %>% filter(year==2013) %>% group_by(product_type) %>% summarize(m=mean(price_doc, na.rm=T),esd=sd(price_doc,na.rm=T)) %>% right_join(cv2,by=c("product_type")) %>% mutate(pred2 = pred*esd+m)
# sqrt(mean((log(cv2$pred2)-log(cv2$price_doc))^2))
prediction <- predict(gbdt,dtest)
cat(mean(prediction))
ggplot(data.frame(p=prediction), aes(x=p)) + geom_density()+geom_density(data=train, aes(x=price_norm), color="red")
test2 <- test %>% bind_cols(data.frame(pred=prediction))
test2 <- train %>% filter(year_quarter %in% c("2013_3", "2013_4", "2014_1")) %>% group_by(product_type) %>% summarize(m=mean(price_doc, na.rm=T),esd=sd(price_doc,na.rm=T)) %>% right_join(test2,by="product_type") %>% mutate(pred2 = pred*esd+m)
sample_submission$price_doc <- test2$pred2
mean(test2$pred2)
range(test2$pred2)
write.csv(sample_submission, "XGB_R_output_5.csv", row.names = F)
imp_matrix_all <- xgb.importance(colnames(dtrain),gbdt)
ggplot(head(imp_matrix_all,50),aes(x=reorder(Feature,Gain),y=Gain))+geom_bar(stat="identity")+coord_flip(ylim=c(0,0.4))+theme_bw()+labs(x="")
# bind cv predictions to train
train2 <- train %>% filter(id %in% train_id) %>% bind_cols(data.frame(pred=res$pred)) %>% mutate(set="train")
my5 <- fread('XGB_R_output_5.csv')
r <- data.frame(id=andy1$id, a1=andy1$price_doc, a2=andy2$price_doc, m1=my1$price_doc, m2=my2$price_doc, m3=my3$price_doc, m4=my4$price_doc, m5=my5$price_doc)
cor(r[,2:7])
cor(r[,2:8])
pred <- data.frame(id=r$id, price_doc = round(0.5*r$a1 + 0.5*r$m5))
mean(pred$price_doc)
fwrite(pred, 'last1.csv')
getwd()
fwrite(pred, 'last1.csv')
pred <- data.frame(id=r$id, price_doc = round(0.2*r$a1 + 0.8*r$m5))
fwrite(pred, 'last1.csv')
fwrite(pred, 'last1.csv')
fwrite(pred, 'last1.csv')
800*0.95
test2 <- test %>% bind_cols(data.frame(pred=prediction))
test2 <- train %>% filter(year_quarter %in% c("2012_4", "2013_1")) %>% group_by(product_type) %>% summarize(m=mean(price_doc, na.rm=T),esd=sd(price_doc,na.rm=T)) %>% right_join(test2,by="product_type") %>% mutate(pred2 = pred*esd+m)
sample_submission$price_doc <- test2$pred2
mean(test2$pred2)
test2 <- test %>% bind_cols(data.frame(pred=prediction))
test2 <- train %>% filter(year_quarter %in% c("2012_4", "2013_1", "2013_2")) %>% group_by(product_type) %>% summarize(m=mean(price_doc, na.rm=T),esd=sd(price_doc,na.rm=T)) %>% right_join(test2,by="product_type") %>% mutate(pred2 = pred*esd+m)
sample_submission$price_doc <- test2$pred2
mean(test2$pred2)
test2 <- test %>% bind_cols(data.frame(pred=prediction))
test2 <- train %>% filter(year_quarter %in% c("2013_1", "2013_2")) %>% group_by(product_type) %>% summarize(m=mean(price_doc, na.rm=T),esd=sd(price_doc,na.rm=T)) %>% right_join(test2,by="product_type") %>% mutate(pred2 = pred*esd+m)
sample_submission$price_doc <- test2$pred2
mean(test2$pred2)
range(test2$pred2)
write.csv(sample_submission, "XGB_R_output_5.csv", row.names = F)
my5 <- fread('XGB_R_output_5.csv')
r <- data.frame(id=andy1$id, a1=andy1$price_doc, a2=andy2$price_doc, m1=my1$price_doc, m2=my2$price_doc, m3=my3$price_doc, m4=my4$price_doc, m5=my5$price_doc)
pred <- data.frame(id=r$id, price_doc = round(0.2*r$a1 + 0.8*r$m5))
fwrite(pred, 'last1.csv')
fwrite(pred, 'last1.csv')
fwrite(pred, 'last1.csv')
setwd("~/Desktop/Machine Learning/Kaggle/instacart/scripts")
rm(list=ls())
gc()
library(data.table)
library(dplyr)
library(tidyr)
library(xgboost)
library(stringr)
library(ModelMetrics)
library(ggplot2)
#setwd("D:/Eigene Dateien/sonstiges/Kaggle/instacart/scripts")
f1 <- function (y, pred)
{
tp <- sum(pred==1 & y == 1)
fp <- sum(pred==1 & y == 0)
fn <- sum(pred==0 & y == 1)
precision <- ifelse ((tp==0 & fp==0), 0, tp/(tp+fp)) # no reorders predicted
recall <- ifelse ((tp==0 & fn==0), 0, tp/(tp+fn)) # no products reordered
score <- ifelse((all(pred==0) & all(y==0)),1,ifelse((precision==0 & recall==0),0,2*precision*recall/(precision+recall)))
score
}
# Load Data ---------------------------------------------------------------
path <- "../input"
aisles <- fread(file.path(path, "aisles.csv"))
departments <- fread(file.path(path, "departments.csv"))
opp <- fread(file.path(path, "order_products__prior.csv"))
opt <- fread(file.path(path, "order_products__train.csv"))
ord <- fread(file.path(path, "orders.csv"))
products <- fread(file.path(path, "products.csv"))
# add user_id to train orders
opt$user_id <- ord$user_id[match(opt$order_id, ord$order_id)]
train_info <- opt[,.(sum_products = .N, sum_reordered=sum(reordered)),user_id]
# join products with order info for all prior orders
setkey(opp,order_id)
setkey(ord,order_id)
op <- merge(ord,opp,all=FALSE) # inner join filter
rm(opp)
gc()
# Get the only reorderes ------------------------------
reorder_users <- op[order_number>1,.(mean_reordered = mean(reordered), n=.N), user_id][mean_reordered==1,user_id]
gc()
# Take subset of Data ----------------------------------------------------
test_users <- unique(ord[eval_set=="test", user_id])
train_users <- unique(ord[eval_set=="train", user_id]) #& !user_id %in% reorder_users
n_users <- 15000
all_train_users <- train_users[1:n_users]
all_users <- c(all_train_users, test_users)
setkeyv(op,c("user_id","product_id", "order_number"))
op[,last_prior_order := max(order_number),.(user_id)]
ord[,last_order := max(order_number),.(user_id)] # auch train/test orders mit drin
#op<-op[last_prior_order-order_number <= 2] #last order = last prior order
#ord<-ord[last_order-order_number <= 3]
setkey(ord, user_id, order_number)
ord[order(order_number), ':=' (order_days_sum = cumsum(ifelse(is.na(days_since_prior_order),0,days_since_prior_order))),user_id][,':=' (order_days_max=max(order_days_sum)),user_id][, ':=' (order_day_year = 365-(order_days_max-order_days_sum)),user_id]
op <- merge(op, ord[,.(user_id, order_number, order_days_sum, order_days_max, order_day_year)], all.x=T)
op[order(user_id, product_id, order_number), ':=' (
product_time = 1:.N,
first_order = min(order_number),
second_order = order_number[2],
up_sum_order = .N), .(user_id,product_id)]
op[(reordered==1 | product_time==1),':=' (order_days_lag=c(NA,order_days_sum[-.N])), .(user_id, product_id)]
# Products ----------------------------------------------------------------
prd <- op[, .(
prod_orders = .N,
prod_maxorders = max(product_time),
prod_reorders = sum(reordered),
prod_first_orders = sum(product_time==1),
prod_second_orders = sum(product_time==2),
prod_add_to_cart = mean(add_to_cart_order),
prod_inpercent_orders=mean(up_sum_order/last_prior_order),
prod_inpercent_afterfirst = mean(up_sum_order/(last_prior_order-first_order+1)),
prod_popularity = mean(uniqueN(user_id)),
prod_season = mean(order_day_year),
prod_orders_till_first_reorder = mean(second_order-first_order,na.rm=T)
), product_id][,':=' (
prod_reorder_probability = prod_second_orders / prod_first_orders,
prod_reorder_times = 1 + prod_reorders / prod_first_orders,
prod_reorder_ratio = prod_reorders / prod_orders,
prod_reorders = NULL,
prod_first_orders = NULL,
prod_second_orders = NULL
)]
# do the subsetting after product features were created
op<-op[user_id %in% all_users]
opt<-opt[user_id %in% all_users]
ord<-ord[user_id %in% all_users]
products[, ':=' (prod_organic = ifelse(str_detect(str_to_lower(product_name),'organic'),1,0))]
products[, ':=' (product_name = NULL)]
setkey(products,product_id)
setkey(prd, product_id)
setkey(op, product_id)
prd <- merge(prd, products[,.(product_id, aisle_id, department_id)], all.x=TRUE)
op <- merge(op, products[,.(product_id, aisle_id, department_id)], all.x=TRUE)
rm(products)
gc()
# Users -------------------------------------------------------------------
users <- ord[eval_set=="prior", .(user_orders=.N,
user_period=sum(days_since_prior_order, na.rm = T),
user_mean_days_since_prior = mean(days_since_prior_order, na.rm = T),
user_std_days_since_prior_order = sd(days_since_prior_order, na.rm=T)
), user_id]
us <- op[,.(
user_total_products = .N,
user_reorder_ratio = sum(reordered == 1) / sum(order_number > 1),
user_distinct_products = uniqueN(product_id),
user_distinct_aisles = uniqueN(aisle_id),
user_distinct_depts = uniqueN(department_id)
), user_id][,':=' (user_pct_distinct_products = user_distinct_products / user_total_products,
user_pct_distinct_aisles = user_distinct_aisles / user_total_products,
user_pct_distinct_depts = user_distinct_depts / user_total_products)]
users <- merge(users, us, all=FALSE)
us <- op[,.(user_order_products = .N),.(user_id,order_id)][,.(user_order_products_min=min(user_order_products),user_order_products_max=max(user_order_products),user_order_products_sd=sd(user_order_products)), user_id]
users <- merge(users, us, all=FALSE)
us <- op[(last_prior_order-order_number)<=1, .(user_order_products_2 = .N, mean_reordered=mean(reordered)), .(user_id, order_id)][,.(user_order_products_2 = mean(user_order_products_2), user_reorder_rate_2=mean(mean_reordered)), user_id]
users <- merge(users, us, all=FALSE)
users[,':=' (user_average_basket = user_total_products / user_orders)]
us <- ord[eval_set != "prior", .(user_id,
order_id,
eval_set,
train_time_since_last_order = days_since_prior_order,
train_dow = order_dow,
train_how = order_hour_of_day,
train_ordernum = order_number,
train_season = order_day_year)]
setkey(users, user_id)
setkey(us, user_id)
users <- merge(users, us, all=FALSE)
rm(us)
gc()
# Departments -------------------------------------------------------------
dep <- op[,.(dept_total_products = .N,
dept_total_orders = uniqueN(order_id),
dept_total_users = uniqueN(user_id),
dept_reorder_times = sum(reordered),
dept_reorder_ratio = mean(reordered)), department_id][,':='
(dept_products_per_order = dept_total_products / dept_total_orders)]
# Database ----------------------------------------------------------------
data <- op[, .(
up_orders = .N,
up_first_order = min(order_number),
up_last_order = max(order_number),
up_last_order_dow = order_dow[order_number==max(order_number)],
up_last_order_hod = order_hour_of_day[order_number==max(order_number)],
up_avg_cart_position = mean(add_to_cart_order),
up_avg_days_since_reorder = mean(order_days_sum-order_days_lag,na.rm=T)),
.(user_id, product_id)]
setkey(users,user_id)
setkey(data,user_id)
data <- merge(data,users,all=FALSE)
setkey(prd,product_id)
setkey(data,product_id)
data <- merge(data,prd,all=FALSE)
rm(op, ord)
data[,':=' (
up_diff_train_typical = abs(train_time_since_last_order-up_avg_days_since_reorder),
up_perc_diff_train_typical = train_time_since_last_order/up_avg_days_since_reorder
)]
#setkey(dep,department_id)
#setkey(data,department_id)
#data <- merge(data,dep,all=FALSE)
rm(prd, users, dep)
gc()
data[,':=' (up_order_rate = up_orders / user_orders,
up_orders_since_last_order = user_orders - up_last_order,
up_inpercent_afterfirst = up_orders / (user_orders - up_first_order + 1))]
# merge in train order
setkey(opt, user_id, product_id)
setkey(data, user_id, product_id)
data <- merge(data, opt[,.(user_id, product_id, reordered)], all.x=TRUE)
rm(opt)
gc()
# do it the data.table way
# Train / Test datasets ---------------------------------------------------
train <- data[eval_set == "train"]
train_userid <- train[,user_id]
train[,':=' (eval_set=NULL, product_id=NULL)]
train[is.na(reordered), ':=' (reordered=0)]
test <-data[eval_set == "test"]
test[,':=' (eval_set=NULL, reordered=NULL)]
rm(data)
gc()
# Model fitting ---------------------------------------------------------
colnames(train)
# Setting params for fitting
params <- list(
"objective"           = "reg:logistic",
"eval_metric"         = "auc",
"eta"                 = 0.1,
"max_depth"           = 6,
"min_child_weight"    = 10,
"gamma"               = 0.7,
"subsample"           = 0.95,
"colsample_bytree"    = 0.95
)
# Get the folds ---------------------------------
# 131,209 users in total
users_per_fold <- 5000
n_fold <- 3
# create the folds
val_users_random <- sample(unique(train_userid), size = n_fold*users_per_fold, replace = FALSE)
if (n_fold ==1) {
val_user_groups <- 1
} else {
val_user_groups <- cut(1:length(val_users_random),n_fold,labels=FALSE)
}
folds <- list()
for (i in 1:n_fold) {
folds[[i]] <- which(train_userid %in% val_users_random[val_user_groups==i])
}
# Do the CV ------------------------------------
threshold <- 0.20
n_rounds <- 80
calc_f1_every_n <- 10
res<-list()
res$f1 <- matrix(0,n_rounds/calc_f1_every_n,n_fold)
res$mean_reordered <- matrix(0,n_rounds/calc_f1_every_n,n_fold)
for (i in 1:length(folds)) {
cat('Training on fold', i,'...\n')
cv_train <- train[-folds[[i]],]
cv_val <- train[folds[[i]],]
dtrain <- xgb.DMatrix(data.matrix(select(cv_train,-user_id,-order_id,-reordered)),label=cv_train$reordered)
dval <- xgb.DMatrix(data.matrix(select(cv_val,-user_id,-order_id,-reordered)),label=cv_val$reordered)
watchlist <- list(train=dtrain, val=dval)
train_users <- cv_train$user_id
for (j in 1:(n_rounds/calc_f1_every_n)){
if (j==1){
bst <- xgb.train(params,dtrain,calc_f1_every_n, watchlist=watchlist) # first boosting iteration
} else {
bst <- xgb.train(params,dtrain,calc_f1_every_n, watchlist=watchlist, xgb_model=bst) # incremental boost
}
pred<-predict(bst,dval)
y <- getinfo(dval,'label')
valid_users <- cv_val$user_id
dt <- data.table(user_id=valid_users, y=y, pred=pred, ypred=(pred>threshold)*1)
f1_score <- dt[,.(f1score = f1(y,ypred)), user_id][,.(f1_mean=mean(f1score))]
cat('val-f1: ', f1_score$f1_mean, 'mean sum_pred: ',dt[,.(sp = sum(ypred)),user_id][,.(mean_sp = mean(sp))]$mean_sp, '\n')
res$f1[j,i] <- f1_score$f1_mean
res$mean_reordered[j,i] <- mean(cv_val$reordered)
}
}
results <- data.frame(m=rowMeans(res$f1),sd=apply(res$f1,1,sd),res$f1, res$mean_reordered)
results
best_iter <- which.max(results$m)*calc_f1_every_n
n_rounds <- best_iter
dtrain <- xgb.DMatrix(as.matrix(train %>% select(-user_id,-reordered)), label = train$reordered)
watchlist <- list(train = dtrain)
model <- xgb.train(data = dtrain, params = params, nrounds = n_rounds, watchlist=watchlist)
importance <- xgb.importance(colnames(dtrain), model = model)
xgb.ggplot.importance(importance)+theme(axis.text.y = element_text(hjust = 0))
train<-as.data.table(train)
setkey(train, user_id)
dtest <- xgb.DMatrix(as.matrix(test[,-c("user_id","product_id"),with=FALSE]))
test$pred <- predict(model, dtest)
test[,reordered:=(pred>0.2)*1]
submission <- test[reordered==1,.(products = paste(product_id, collapse = " ")), order_id]
missing <- data.table(
order_id = unique(test$order_id[!test$order_id %in% submission$order_id]),
products = "None"
)
submission <- rbindlist(list(submission, missing))
tmpp <- dt[order(-pred)][,omp := 1-pred][,p_none := prod(omp), order_id]
fwrite(submission[order(order_id)], file = "submit.csv")
